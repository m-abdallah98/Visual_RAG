# Visual_RAG
## Multimodality Experiments

A collection of experiments for exploring multimodal retrieval and similarity methods.  
This repository hosts a Jupyter notebook demonstrating how to load, preprocess, and compare text and image embeddings using various libraries (NumPy, Pandas, Gensim, scikit-learn, Hugging Face Hub, etc.).

## ðŸ“‚ Project Structure

### Multimodality_Experiments
-  Multimodality_Experiments.ipynb
-  README.md
-  requirements.txt
